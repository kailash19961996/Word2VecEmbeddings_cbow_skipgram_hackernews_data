{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "A72MHW3pVq5P",
        "outputId": "db0ba109-398a-4dac-d4ae-1cbcefd6ea54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\npip install wikipedia\\n\\nimport wikipedia\\nfrom tqdm import tqdm\\n\\n# Set the language of Wikipedia to English\\nwikipedia.set_lang('en')\\n\\n# Fetch Wikipedia articles\\narticles = []\\nnum_texts = 120\\n\\nfor title in tqdm(wikipedia.random(pages=num_texts), total=num_texts):\\n    try:\\n        page = wikipedia.page(title)\\n        article_content = page.content\\n        articles.append(article_content)\\n    except (wikipedia.exceptions.PageError,\\n            wikipedia.exceptions.DisambiguationError,\\n            wikipedia.exceptions.HTTPTimeoutError):\\n        # Handle exceptions by skipping the current article\\n        continue\\n\\n# File path to save the text file\\nfile_path = 'output.txt'\\n\\nwith open(file_path, 'wt', encoding='utf-8') as f:\\n    for article in articles:\\n        f.write(article + '\\n')\\n        \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 287
        }
      ],
      "source": [
        "\"\"\"\n",
        "pip install wikipedia\n",
        "\n",
        "import wikipedia\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set the language of Wikipedia to English\n",
        "wikipedia.set_lang('en')\n",
        "\n",
        "# Fetch Wikipedia articles\n",
        "articles = []\n",
        "num_texts = 120\n",
        "\n",
        "for title in tqdm(wikipedia.random(pages=num_texts), total=num_texts):\n",
        "    try:\n",
        "        page = wikipedia.page(title)\n",
        "        article_content = page.content\n",
        "        articles.append(article_content)\n",
        "    except (wikipedia.exceptions.PageError,\n",
        "            wikipedia.exceptions.DisambiguationError,\n",
        "            wikipedia.exceptions.HTTPTimeoutError):\n",
        "        # Handle exceptions by skipping the current article\n",
        "        continue\n",
        "\n",
        "# File path to save the text file\n",
        "file_path = 'output.txt'\n",
        "\n",
        "with open(file_path, 'wt', encoding='utf-8') as f:\n",
        "    for article in articles:\n",
        "        f.write(article + '\\n')\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data exploration\n",
        "\n",
        "file = open(\"output.txt\",'r')\n",
        "wiki_corpus = file.readlines()\n",
        "file.close\n",
        "\n",
        "\n",
        "print(wiki_corpus[3:5])\n",
        "print(len(wiki_corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGDcrq92WGwl",
        "outputId": "bad2a34c-e004-401d-e170-57976e382ab9"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bouthaina Shaaban, Syrian politician\\n', 'Bouthayna Shaya, Syrian actress and voice actress\\n']\n",
            "3579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(wiki_corpus)):\n",
        "  wiki_corpus[i] = wiki_corpus[i].lower().replace('\\n', '')\n",
        "\n",
        "print(wiki_corpus[3:5])\n",
        "print(len(wiki_corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPepgHi9WJpU",
        "outputId": "e5ab8410-899b-46bb-8a8f-89211a5a3ffd"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bouthaina shaaban, syrian politician', 'bouthayna shaya, syrian actress and voice actress']\n",
            "3579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tokens\n",
        "\n",
        "tokens = []\n",
        "\n",
        "for sentence in wiki_corpus:\n",
        "  temp = []\n",
        "  for word in sentence.split():\n",
        "    temp.append(word)\n",
        "  tokens.append(temp)\n",
        "\n",
        "print(tokens[3:5])\n",
        "print(len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB5hgoSKYdol",
        "outputId": "cf6aea4b-8e4f-4f03-d9f0-946d603affc4"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['bouthaina', 'shaaban,', 'syrian', 'politician'], ['bouthayna', 'shaya,', 'syrian', 'actress', 'and', 'voice', 'actress']]\n",
            "3579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding unique words\n",
        "\n",
        "vocabulary = []\n",
        "\n",
        "for sentence in tokens:\n",
        "  vocabulary.extend(sentence)\n",
        "\n",
        "print(vocabulary[:5])\n",
        "print(len(vocabulary))\n",
        "\n",
        "vocabulary = list(set(vocabulary))\n",
        "print(vocabulary[:5])\n",
        "print(len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMC_vg54WMkL",
        "outputId": "3efa7707-4a2a-44e8-f137-4cb7b26d7990"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['boutheina', '(also', 'spelled', 'bothayna', 'or']\n",
            "62544\n",
            "['shirvanshahs', 'ohio', 'regular', 'contributor)', 'lead']\n",
            "15652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentencepiece\n",
        "\n",
        "import sentencepiece as spm\n",
        "import torchtext"
      ],
      "metadata": {
        "id": "5XMREP_hWPWX"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spm.SentencePieceTrainer.Train('--input=output.txt --model_prefix=model_1 --vocab_size=10000')\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('model_1.model')\n",
        "\n",
        "sp.get_piece_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5UMtUM_We_k",
        "outputId": "c6afd6c2-0543-4ff2-8f49-675978da2d28"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sp.encode_as_pieces('Eli lilly!'))\n",
        "print(sp.encode_as_ids('Eli lilly!'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1pQ3IAZW9Im",
        "outputId": "ca5c07c3-bacc-49fe-d150-8965688a3e8b"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁E', 'li', '▁li', 'lly', '!']\n",
            "[74, 1610, 1714, 1599, 976]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sp.decode_pieces(['▁E', 'li', '▁li', 'lly', '!']))\n",
        "print(sp.decode_ids([74, 1610, 1714, 1599, 976]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKe5eTf_ZQIn",
        "outputId": "e75a0515-76c8-444d-9b23-be6545cfd804"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eli lilly!\n",
            "Eli lilly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding using gensim in word2vec format\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "def tokenize_and_embed(filepath):\n",
        "\n",
        "  with open(filepath, 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "  tokens = sp.encode_as_pieces(text)\n",
        "\n",
        "  model = Word2Vec(sentences = [tokens], vector_size = 50, min_count = 1)\n",
        "  word2vec_embedding = model.wv\n",
        "\n",
        "  return word2vec_embedding\n",
        "\n",
        "embeddings = tokenize_and_embed(\"/content/output.txt\")"
      ],
      "metadata": {
        "id": "w4jUIieXZh-m"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The length of the embedding is {len(embeddings)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYZOzAMSajdQ",
        "outputId": "9baa5071-ac01-4023-8c6a-d641a400b6d9"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the embedding is 9746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.index_to_key[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kezsoq-Telye",
        "outputId": "baf8f73f-d26a-40db-d112-826031698322"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[',', '▁the', '.', 's', '▁']"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in embeddings.index_to_key[:5]:\n",
        "  embedding = embeddings[word]\n",
        "  print(f\"{word}\")\n",
        "  print(f\"Embedding: {embedding}\")\n",
        "  print(f\"length is {len(embedding)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze95YUHfb-t3",
        "outputId": "18ca1349-2e76-4553-8483-191a28c60e41"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",\n",
            "Embedding: [-0.15821798  0.13665175  0.10172564 -0.21292017 -0.17330092 -0.08970051\n",
            "  0.30831704  0.16143093 -0.51108974 -0.06177684  0.08528311 -0.28096092\n",
            "  0.21434954 -0.1873156  -0.03638269  0.0653494   0.42317116  0.19100742\n",
            " -0.46234775 -0.4033026   0.15554841  0.31748298  0.52794516 -0.07680685\n",
            "  0.6703945   0.23705672 -0.03625747 -0.02997481 -0.40711364 -0.05873359\n",
            " -0.14257386 -0.09305119 -0.10717768 -0.17465073 -0.07319134 -0.03081069\n",
            "  0.42560765 -0.01629002  0.18698648 -0.29209745  0.14180495 -0.0508297\n",
            " -0.24794997  0.12888551  0.3618283  -0.25009656  0.0471344  -0.1930906\n",
            "  0.00328653  0.3401396 ]\n",
            "length is 50\n",
            "▁the\n",
            "Embedding: [-0.21542375  0.17808495  0.10409442 -0.28904685 -0.17329203 -0.10410284\n",
            "  0.37617794  0.16310264 -0.6295749  -0.04979402  0.0826259  -0.34410292\n",
            "  0.27059838 -0.2641184  -0.03553003  0.08953472  0.51768506  0.24261105\n",
            " -0.55695647 -0.47323278  0.18559986  0.39946407  0.6351292  -0.11207359\n",
            "  0.82369816  0.30535495 -0.02723609 -0.05178813 -0.49211255 -0.08261207\n",
            " -0.16284673 -0.10859337 -0.14647865 -0.18221948 -0.09698987 -0.02922348\n",
            "  0.52158266 -0.0130814   0.22245419 -0.33630905  0.20372859 -0.07406469\n",
            " -0.27812076  0.17164867  0.46387246 -0.29810053  0.06108339 -0.28066787\n",
            " -0.00731331  0.41258806]\n",
            "length is 50\n",
            ".\n",
            "Embedding: [-0.1772772   0.14519206  0.10314696 -0.22198483 -0.14006035 -0.08921115\n",
            "  0.30072019  0.1542861  -0.5103093  -0.06626009  0.07067576 -0.29699808\n",
            "  0.21372403 -0.18920411 -0.0180942   0.08343142  0.43397784  0.2049482\n",
            " -0.45513037 -0.38755468  0.14700975  0.30159464  0.5351728  -0.09881131\n",
            "  0.6761883   0.2531363  -0.04396461 -0.03286471 -0.39750034 -0.03971819\n",
            " -0.10802779 -0.10240716 -0.12894705 -0.16826163 -0.06176744 -0.02018201\n",
            "  0.4249089   0.00915731  0.206976   -0.26465976  0.17854099 -0.07500956\n",
            " -0.24884051  0.1397803   0.35484654 -0.23521408  0.07547662 -0.21881928\n",
            " -0.00439956  0.3258563 ]\n",
            "length is 50\n",
            "s\n",
            "Embedding: [-0.12002555  0.09534218  0.07532381 -0.19204733 -0.13399296 -0.04518781\n",
            "  0.27109838  0.1339998  -0.42789716 -0.02890393  0.03893643 -0.23165123\n",
            "  0.17955762 -0.18215615 -0.01290586  0.07053579  0.37156677  0.14842054\n",
            " -0.36306188 -0.3127532   0.11391845  0.24259634  0.45166403 -0.05122242\n",
            "  0.55986196  0.19318704 -0.04221481 -0.04266589 -0.32426012 -0.05245932\n",
            " -0.12947167 -0.06968615 -0.09766057 -0.14901    -0.0538445  -0.02800804\n",
            "  0.34801188 -0.02369265  0.16573061 -0.24947955  0.13878572 -0.05726597\n",
            " -0.1929067   0.10169958  0.3011581  -0.20703547  0.06498642 -0.18894815\n",
            " -0.02507417  0.2821894 ]\n",
            "length is 50\n",
            "▁\n",
            "Embedding: [-0.1768027   0.1580999   0.08460713 -0.25961152 -0.15295781 -0.06866144\n",
            "  0.31548503  0.16187057 -0.5699521  -0.04614671  0.06380782 -0.31298357\n",
            "  0.26709515 -0.21530546 -0.01043972  0.0630312   0.4723539   0.22867325\n",
            " -0.5099143  -0.4353557   0.13829376  0.32913482  0.5580211  -0.10136171\n",
            "  0.74288565  0.260066   -0.02050346 -0.03184238 -0.44608048 -0.04809438\n",
            " -0.12955679 -0.11720058 -0.15427592 -0.18086287 -0.0921342  -0.03280389\n",
            "  0.44923565  0.00492617  0.20557255 -0.31439406  0.16367403 -0.06314932\n",
            " -0.25646892  0.16387928  0.40502393 -0.2627359   0.07294173 -0.24108657\n",
            " -0.0177246   0.3547009 ]\n",
            "length is 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings['the'], embeddings['the'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FZh3Rtha957",
        "outputId": "6ce4d970-bd6d-4932-9bc6-2c570314a473"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1.4755122e-02,  1.6703237e-02, -6.7306925e-03,  7.0618093e-03,\n",
              "        -1.6353590e-02, -9.0560876e-03, -5.8977380e-03,  1.9603815e-02,\n",
              "        -2.2777053e-02, -2.5047460e-03,  1.8867176e-02, -1.8022401e-05,\n",
              "         1.0996536e-02,  1.1844702e-02, -7.6020239e-03, -7.6250988e-03,\n",
              "        -9.6891355e-03, -5.6149662e-03, -6.5517779e-03,  1.2277971e-02,\n",
              "        -2.3040778e-03,  8.9241695e-03,  1.3468783e-02,  1.0891717e-02,\n",
              "         4.8256754e-03,  9.4104540e-03,  1.2818528e-02, -1.5557145e-02,\n",
              "         6.3929046e-03, -1.9859388e-02, -5.3406367e-03, -7.4768914e-03,\n",
              "         4.9003791e-03,  1.9406274e-04, -2.5476601e-03,  7.0284400e-03,\n",
              "         2.0419199e-02,  1.1902789e-02, -1.5950717e-02, -9.4479499e-03,\n",
              "        -3.9276760e-03,  1.7385030e-02,  3.8404425e-03,  5.1047145e-03,\n",
              "         1.7041249e-02, -8.6543644e-03, -7.6797637e-03, -1.5518800e-02,\n",
              "        -4.7737965e-03,  1.3970410e-02], dtype=float32),\n",
              " (50,))"
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing our new data\n",
        "\n",
        "with open('Royal_data.txt', 'r') as f:\n",
        "  new_data = f.readlines()\n",
        "  f.close\n",
        "\n",
        "print(len(new_data))\n",
        "print(new_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN6f9jSsbLxV",
        "outputId": "4bc34d63-8583-430f-f623-6459c51fe01c"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "['The future king is the prince\\n', 'Daughter is the princess\\n', 'Son is the prince\\n', 'Only a man can be a king\\n', 'Only a woman can be a queen\\n', 'The princess will be a queen\\n', 'The prince is a strong man\\n', 'The princess is a beautiful woman\\n', 'Prince is only a boy now\\n', 'Prince will be king\\n', 'A boy will be a man']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define a function to handle word embeddings\n",
        "def get_embedding(word, embeddings):\n",
        "  # Check if the word exists in the vocabulary\n",
        "  if word in embeddings:\n",
        "    return embeddings[word]\n",
        "  else:\n",
        "    # Handle unknown words (e.g., average vector, random vector)\n",
        "    return np.zeros(embeddings.vector_size)  # Zero vector for unknown words\n",
        "\n",
        "\n",
        "\n",
        "# Create a list to store word embeddings for the new data\n",
        "new_data_embeddings = []\n",
        "\n",
        "for text in new_data:\n",
        "  # Preprocess the text (e.g., tokenization, lowercase)\n",
        "  text = text.lower()  # Simple example, adjust pre-processing as needed\n",
        "  tokens = sp.encode_as_pieces(text)\n",
        "  print(tokens)\n",
        "\n",
        "  # Get word embeddings for each token and average them\n",
        "  text_embedding = np.mean([get_embedding(token, embeddings) for token in tokens], axis=0)\n",
        "  new_data_embeddings.append(text_embedding)\n",
        "\n",
        "new_data_embeddings[0:2], len(new_data_embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z9zo-HXoaq1",
        "outputId": "25ba39fc-6b00-4f2b-d970-9c9fe0ba0e4d"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁the', '▁fu', 'ture', '▁king', '▁is', '▁the', '▁pr', 'ince']\n",
            "['▁daughter', '▁is', '▁the', '▁pr', 'ince', 's', 's']\n",
            "['▁son', '▁is', '▁the', '▁pr', 'ince']\n",
            "['▁on', 'ly', '▁a', '▁man', '▁can', '▁be', '▁a', '▁king']\n",
            "['▁on', 'ly', '▁a', '▁woman', '▁can', '▁be', '▁a', '▁quee', 'n']\n",
            "['▁the', '▁pr', 'ince', 's', 's', '▁will', '▁be', '▁a', '▁quee', 'n']\n",
            "['▁the', '▁pr', 'ince', '▁is', '▁a', '▁strong', '▁man']\n",
            "['▁the', '▁pr', 'ince', 's', 's', '▁is', '▁a', '▁be', 'au', 'ti', 'ful', '▁woman']\n",
            "['▁pr', 'ince', '▁is', '▁on', 'ly', '▁a', '▁boy', '▁now']\n",
            "['▁pr', 'ince', '▁will', '▁be', '▁king']\n",
            "['▁a', '▁boy', '▁will', '▁be', '▁a', '▁man']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([-0.0584887 ,  0.04671758,  0.03322815, -0.07456634, -0.04393948,\n",
              "         -0.02910887,  0.10412631,  0.04553461, -0.17704867, -0.01801847,\n",
              "          0.01598099, -0.09317356,  0.06912085, -0.07342655, -0.01406843,\n",
              "          0.02503313,  0.14242955,  0.06450056, -0.15973845, -0.1305278 ,\n",
              "          0.04967967,  0.10948216,  0.17884652, -0.03406755,  0.2243917 ,\n",
              "          0.08994204, -0.01137875, -0.00373624, -0.14020863, -0.01685864,\n",
              "         -0.0509486 , -0.03558093, -0.0393089 , -0.0502714 , -0.02532208,\n",
              "         -0.00863226,  0.13969   ,  0.00076205,  0.0510409 , -0.09248054,\n",
              "          0.05609575, -0.02401601, -0.07151686,  0.05032519,  0.13016705,\n",
              "         -0.08505597,  0.0214482 , -0.07697316, -0.00141675,  0.10806104],\n",
              "        dtype=float32),\n",
              "  array([-0.0685121 ,  0.05638577,  0.04459536, -0.10180177, -0.06281793,\n",
              "         -0.02869456,  0.14473526,  0.06641027, -0.2310745 , -0.02058047,\n",
              "          0.02353842, -0.11906494,  0.09626527, -0.10088223, -0.00923041,\n",
              "          0.03924555,  0.19837199,  0.08415407, -0.20394775, -0.17351739,\n",
              "          0.06401282,  0.135071  ,  0.23799841, -0.03781587,  0.29781508,\n",
              "          0.11371229, -0.01850091, -0.01462288, -0.17890997, -0.02402339,\n",
              "         -0.06359182, -0.04035167, -0.05495271, -0.07455603, -0.02863127,\n",
              "         -0.01018536,  0.18656807, -0.0056395 ,  0.07687838, -0.13179186,\n",
              "          0.07833387, -0.03170869, -0.09988914,  0.05614072,  0.16891436,\n",
              "         -0.11120547,  0.02881426, -0.10053661, -0.00640684,  0.15132199],\n",
              "        dtype=float32)],\n",
              " 11)"
            ]
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings['man']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTXO3dvyyc78",
        "outputId": "1bd5a384-ded9-4ed5-ba86-dd093085d0c9"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00341826,  0.02465613,  0.01783841,  0.00158785,  0.00278857,\n",
              "       -0.00297462,  0.03290349,  0.00417481, -0.05106325,  0.00656121,\n",
              "        0.01420123, -0.00950183, -0.00237943,  0.00171774,  0.00599508,\n",
              "        0.0227341 ,  0.03991064,  0.02076855, -0.03000442, -0.02447276,\n",
              "        0.01256079,  0.0155857 ,  0.0142398 ,  0.0017586 ,  0.03260358,\n",
              "        0.01494514,  0.0056525 , -0.01759565, -0.02613164,  0.01469611,\n",
              "       -0.00548983, -0.02610622, -0.00783861,  0.00857327,  0.00539587,\n",
              "        0.0167386 ,  0.0360363 ,  0.00428325, -0.00484205, -0.02013864,\n",
              "        0.01644858, -0.01868846, -0.02313053,  0.02348558,  0.0209784 ,\n",
              "       -0.00457763, -0.00214687, -0.03169463, -0.00497517,  0.03055826],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(embeddings['is'] + embeddings['the'])/2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg7jq8sRx07K",
        "outputId": "e6ef60da-e74e-47a0-806e-44f8f23301ef"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0192496 ,  0.0011788 , -0.00426882,  0.00085883, -0.00931476,\n",
              "       -0.00205181,  0.00669172,  0.02083366, -0.02579372, -0.00726645,\n",
              "        0.01578971, -0.01387489,  0.01279379,  0.0034175 , -0.00806058,\n",
              "       -0.00173574,  0.00635048,  0.00307376, -0.00514222, -0.00770317,\n",
              "        0.00826695,  0.00581983,  0.02437011,  0.01272547,  0.00440492,\n",
              "        0.0163493 ,  0.00917638, -0.00492582,  0.0035567 , -0.00474111,\n",
              "       -0.00312569, -0.00783431,  0.00193981,  0.00578733, -0.00444977,\n",
              "       -0.00586052,  0.01603447, -0.00117432, -0.01285248, -0.01830493,\n",
              "       -0.00253329,  0.00117634, -0.00668852,  0.01145128,  0.02095903,\n",
              "       -0.00140911,  0.00468783, -0.007789  , -0.0011566 ,  0.01466139],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = np.mean([embeddings['is'], embeddings['the']], axis =0)\n",
        "dummy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRn6tRLhxNO6",
        "outputId": "7b454cf3-40ff-477b-bb2a-cbae4dfc5f35"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0192496 ,  0.0011788 , -0.00426882,  0.00085883, -0.00931476,\n",
              "       -0.00205181,  0.00669172,  0.02083366, -0.02579372, -0.00726645,\n",
              "        0.01578971, -0.01387489,  0.01279379,  0.0034175 , -0.00806058,\n",
              "       -0.00173574,  0.00635048,  0.00307376, -0.00514222, -0.00770317,\n",
              "        0.00826695,  0.00581983,  0.02437011,  0.01272547,  0.00440492,\n",
              "        0.0163493 ,  0.00917638, -0.00492582,  0.0035567 , -0.00474111,\n",
              "       -0.00312569, -0.00783431,  0.00193981,  0.00578733, -0.00444977,\n",
              "       -0.00586052,  0.01603447, -0.00117432, -0.01285248, -0.01830493,\n",
              "       -0.00253329,  0.00117634, -0.00668852,  0.01145128,  0.02095903,\n",
              "       -0.00140911,  0.00468783, -0.007789  , -0.0011566 ,  0.01466139],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# ['daughter', 'is', 'the', 'princess']\n",
        "\n",
        "embeddings['daughter'], embeddings['princess']\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iPty-r4W0Y6D",
        "outputId": "65fe19a9-a965-437a-b526-b126077e5243"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# ['daughter', 'is', 'the', 'princess']\\n\\nembeddings['daughter'], embeddings['princess']\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "y = [100, 30, 120, 200, 50, 45, 150, 300, 5, 500, 350]\n",
        "\n",
        "\n",
        "new_data_embeddings_tensor = torch.tensor(new_data_embeddings)\n",
        "new_data_embeddings_tensor = new_data_embeddings_tensor.float()\n",
        "\n",
        "y_tensor = torch.tensor(y)  # Replace y with your target values\n",
        "y_tensor = y_tensor.float()"
      ],
      "metadata": {
        "id": "j0eB-XvcsKDH"
      },
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define model parameters\n",
        "input_size = embeddings.vector_size\n",
        "print(input_size)\n",
        "\n",
        "n_hidden_units = 128\n",
        "\n",
        "# Model architecture (without class)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(input_size, n_hidden_units),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(n_hidden_units, 1)\n",
        ")\n",
        "\n",
        "criterion = nn.MSELoss()  # Mean squared error loss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "for epoch in range(1000):  # Train for 10 epochs\n",
        "  optimizer.zero_grad()  # Clear gradients before each epoch\n",
        "  outputs = model(new_data_embeddings_tensor)\n",
        "  loss = criterion(outputs, y_tensor)\n",
        "  loss.backward()  # Backpropagation\n",
        "  optimizer.step()  # Update model parameters\n",
        "  if (epoch % 100 == 0):\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7-ygJMipDbd",
        "outputId": "224ae536-fe6f-4e62-d255-d5bf91822045"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "Epoch 1, Loss: 50470.0742\n",
            "Epoch 101, Loss: 49468.2227\n",
            "Epoch 201, Loss: 46607.7305\n",
            "Epoch 301, Loss: 42046.6016\n",
            "Epoch 401, Loss: 36541.7031\n",
            "Epoch 501, Loss: 31339.1328\n",
            "Epoch 601, Loss: 27413.3457\n",
            "Epoch 701, Loss: 24970.6094\n",
            "Epoch 801, Loss: 23806.9883\n",
            "Epoch 901, Loss: 23397.8906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract weights from the first and second linear layers\n",
        "first_layer_weights = model[0].weight.data  # Weights from first linear layer\n",
        "second_layer_weights = model[2].weight.data  # Weights from second linear layer\n",
        "\n",
        "# Extract biases (if needed)\n",
        "first_layer_bias = model[0].bias.data  # Bias from first linear layer\n",
        "second_layer_bias = model[2].bias.data  # Bias from second linear layer\n",
        "\n",
        "# You can access weights and biases for further analysis or saving\n",
        "first_layer_weights.shape, first_layer_bias.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLEyf6iEs2eG",
        "outputId": "f2c2df92-65b9-4b33-a046-2f1a8d814a46"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 50]), torch.Size([128]))"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_layer_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWmVEy7yvIUK",
        "outputId": "72c30a7f-f892-4a94-c8ef-09c3a0208667"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0040,  0.0962,  0.1092,  ...,  0.0219, -0.1181, -0.0226],\n",
              "        [-0.1333,  0.1343, -0.1181,  ..., -0.1010, -0.0138, -0.0042],\n",
              "        [ 0.0835, -0.0508, -0.0057,  ..., -0.1232,  0.1342, -0.0280],\n",
              "        ...,\n",
              "        [-0.0934, -0.0017,  0.0751,  ...,  0.1391,  0.1658, -0.1121],\n",
              "        [-0.0565, -0.0181, -0.0867,  ..., -0.0624,  0.0751,  0.0682],\n",
              "        [-1.1039,  0.9849,  0.9954,  ..., -1.0973, -1.0629,  0.8952]])"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing our prediction data\n",
        "\n",
        "with open('prediction.txt', 'r') as f:\n",
        "  pred_data = f.readlines()\n",
        "  f.close\n",
        "\n",
        "print(len(pred_data))\n",
        "print(pred_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfvufdF1vswp",
        "outputId": "09b6f046-4757-492d-8f34-a0acd1eed2ae"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "['prince is a king']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings['king']\n",
        "\n",
        "# ['the', 'future', 'king', 'is', 'the', 'prince']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVZWf2QRwdhX",
        "outputId": "e91b7c8e-a050-4dba-fa92-21e2ef380282"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.4298125e-05,  3.9429478e-03, -1.5459769e-02, -8.9199580e-03,\n",
              "       -1.6907291e-02,  1.2838637e-03,  1.3465955e-02,  1.6838247e-02,\n",
              "       -2.8736066e-02, -1.7014154e-06, -8.6970851e-03, -1.7211254e-03,\n",
              "       -1.4359734e-02,  1.0985725e-02,  1.4949586e-03,  1.9903922e-02,\n",
              "       -1.4082628e-04, -1.1637617e-02,  5.6815159e-04, -2.1725811e-02,\n",
              "       -9.4473055e-03, -1.0368950e-02, -4.9052117e-03, -7.8403106e-04,\n",
              "       -2.2173332e-04,  6.5942556e-03, -1.6602093e-02,  1.7075479e-02,\n",
              "       -8.6540859e-03, -1.4339705e-02, -1.9728344e-02, -2.0861762e-02,\n",
              "        1.3077459e-03,  1.5472771e-03, -1.1016614e-02, -1.9121943e-03,\n",
              "        2.2075087e-02,  1.0621300e-02,  1.6670739e-02, -1.0366590e-02,\n",
              "        1.7508181e-02,  6.0665756e-03, -2.1607546e-02, -1.2380616e-02,\n",
              "       -8.6373296e-03, -5.4553207e-03, -3.5631363e-03,  4.3178229e-03,\n",
              "        1.6214946e-02,  1.2907632e-02], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to handle word embeddings\n",
        "def get_embedding(word, embeddings):\n",
        "  # Check if the word exists in the vocabulary\n",
        "  if word in embeddings:\n",
        "    return embeddings[word]\n",
        "  else:\n",
        "    # Handle unknown words (e.g., average vector, random vector)\n",
        "    return np.zeros(embeddings.vector_size)  # Zero vector for unknown words\n",
        "\n",
        "\n",
        "\n",
        "# Create a list to store word embeddings for the new data\n",
        "pred_data_embeddings = []\n",
        "\n",
        "for text in pred_data:\n",
        "  # Preprocess the text (e.g., tokenization, lowercase)\n",
        "  tokens = text.lower().split()  # Simple example, adjust pre-processing as needed\n",
        "  print(tokens)\n",
        "\n",
        "  # Get word embeddings for each token and average them\n",
        "  text_embedding = np.mean([get_embedding(token, embeddings) for token in tokens], axis=0)\n",
        "  new_data_embeddings.append(text_embedding)\n",
        "\n",
        "pred_data_embeddings, len(pred_data_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O57DT9_Hv6qq",
        "outputId": "880547f5-c023-41a3-f292-00f24ac60a69"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prince', 'is', 'a', 'king']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([], 0)"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_embeddings_tensor = torch.tensor(embeddings['man']).float()  # Convert unseen data embeddings to tensor\n",
        "predictions = model(pred_embeddings_tensor)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyldZzrnvPA1",
        "outputId": "642b500a-93ed-4212-fbb1-024bfe7f2f99"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([57.9188], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQfvCWszyUBP"
      },
      "execution_count": 314,
      "outputs": []
    }
  ]
}